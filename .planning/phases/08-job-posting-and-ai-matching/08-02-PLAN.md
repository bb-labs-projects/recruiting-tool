---
phase: 08-job-posting-and-ai-matching
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - src/lib/matching/schema.ts
  - src/lib/matching/prompt.ts
  - src/lib/matching/pre-filter.ts
  - src/lib/matching/score.ts
  - src/lib/matching/run-matching.ts
  - src/app/api/matching/run/route.ts
  - src/app/api/matching/status/route.ts
autonomous: true

must_haves:
  truths:
    - "SQL pre-filter eliminates candidates who don't match required specializations, bar admissions, or technical domains"
    - "Claude Haiku 4.5 scores each shortlisted candidate with a decomposed rubric and structured output"
    - "Match results are cached in job_matches table and not re-scored if already cached"
    - "Matching runs asynchronously with status polling (same pattern as CV parsing)"
    - "Scoring prompts never contain PII (no names, emails, phone numbers, employer names)"
  artifacts:
    - path: "src/lib/matching/schema.ts"
      provides: "Zod schema for match score structured output"
      exports: ["MatchScoreSchema", "MatchScore", "CandidateForScoring", "JobForScoring"]
    - path: "src/lib/matching/prompt.ts"
      provides: "Scoring rubric prompt builder with explicit score ranges"
      exports: ["buildScoringPrompt"]
    - path: "src/lib/matching/pre-filter.ts"
      provides: "SQL pre-filter using EXISTS subqueries on junction tables"
      exports: ["preFilterCandidates"]
    - path: "src/lib/matching/score.ts"
      provides: "Claude API scoring call with zodOutputFormat"
      exports: ["scoreCandidate"]
    - path: "src/lib/matching/run-matching.ts"
      provides: "Orchestrator: pre-filter -> load candidate data -> score -> cache"
      exports: ["runMatchingForJob"]
    - path: "src/app/api/matching/run/route.ts"
      provides: "POST endpoint to trigger matching asynchronously"
      exports: ["POST"]
    - path: "src/app/api/matching/status/route.ts"
      provides: "GET endpoint to poll matching status"
      exports: ["GET"]
  key_links:
    - from: "src/lib/matching/run-matching.ts"
      to: "src/lib/matching/pre-filter.ts"
      via: "imports preFilterCandidates"
      pattern: "import.*preFilterCandidates.*from.*pre-filter"
    - from: "src/lib/matching/run-matching.ts"
      to: "src/lib/matching/score.ts"
      via: "imports scoreCandidate and iterates over shortlist"
      pattern: "import.*scoreCandidate.*from.*score"
    - from: "src/lib/matching/run-matching.ts"
      to: "src/lib/dal/job-matches.ts"
      via: "inserts match results and checks cache"
      pattern: "import.*insertMatch.*getMatchByJobAndProfile.*from.*job-matches"
    - from: "src/lib/matching/score.ts"
      to: "@anthropic-ai/sdk"
      via: "Claude API call with zodOutputFormat"
      pattern: "anthropic\\.messages\\.create"
    - from: "src/app/api/matching/run/route.ts"
      to: "src/lib/matching/run-matching.ts"
      via: "triggers matching pipeline"
      pattern: "import.*runMatchingForJob.*from.*run-matching"
---

<objective>
Build the two-stage AI matching pipeline: SQL pre-filter for candidate elimination, Claude Haiku 4.5 for scoring with structured output, result caching, and async API routes for triggering/polling.

Purpose: This is the core differentiator of the platform -- AI-powered candidate ranking. The two-stage approach keeps costs at ~$0.10-0.15 per job while providing detailed scoring explanations.
Output: Complete matching pipeline (7 files) that can be triggered via API and polled for status.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-job-posting-and-ai-matching/08-RESEARCH.md
@.planning/phases/08-job-posting-and-ai-matching/08-01-SUMMARY.md

Key reference files:
@src/lib/cv-parser/parse.ts -- Claude API + zodOutputFormat pattern to replicate
@src/lib/cv-parser/schema.ts -- Zod schema pattern for structured output
@src/lib/cv-parser/prompt.ts -- Prompt template pattern
@src/lib/dal/employer-profiles.ts -- EXISTS subquery pattern for pre-filtering (buildFilterConditions)
@src/lib/dal/job-matches.ts -- match result DAL (created in plan 01)
@src/lib/dal/jobs.ts -- job DAL (created in plan 01)
@src/lib/anonymize.ts -- bucketExperienceYears function for computing experience
@src/app/api/admin/cv/parse/route.ts -- async API route pattern
@src/app/api/admin/cv/status/route.ts -- status polling API pattern
@src/lib/auth/require-admin.ts -- auth guard for API routes
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create matching schema, prompt, pre-filter, and scoring modules</name>
  <files>src/lib/matching/schema.ts, src/lib/matching/prompt.ts, src/lib/matching/pre-filter.ts, src/lib/matching/score.ts</files>
  <action>
**In `src/lib/matching/schema.ts`:**

Define the Zod schema for Claude's structured output response. This must match exactly what the prompt asks Claude to return:

```typescript
import { z } from 'zod'

const DimensionScore = z.object({
  score: z.number().int().min(0).max(100),
  explanation: z.string(),
})

export const MatchScoreSchema = z.object({
  overallScore: z.number().int().min(0).max(100),
  specializationMatch: DimensionScore,
  experienceFit: DimensionScore,
  technicalBackground: DimensionScore,
  locationMatch: DimensionScore,
  barAdmissions: DimensionScore,
  summary: z.string(),
  recommendation: z.enum(['Strong Match', 'Good Match', 'Partial Match', 'Weak Match']),
})

export type MatchScore = z.infer<typeof MatchScoreSchema>
```

Also define TypeScript types for data passed to the scoring prompt (NO PII):

```typescript
export type JobForScoring = {
  title: string
  description: string | null
  requiredSpecializations: string[]
  preferredSpecializations: string[]
  minimumExperience: number | null
  preferredLocation: string | null
  requiredBar: string[]
  requiredTechnicalDomains: string[]
}

export type CandidateForScoring = {
  specializations: string[]
  experienceYears: number
  education: { institution: string; degree: string; field: string }[]
  barAdmissions: string[]
  technicalDomains: string[]
}
```

CRITICAL: `CandidateForScoring` must NEVER include name, email, phone, or employer names. This is an anonymized scoring DTO.

**In `src/lib/matching/prompt.ts`:**

Export `buildScoringPrompt(job: JobForScoring, candidate: CandidateForScoring): string`.

Use the exact prompt template from 08-RESEARCH.md. The prompt must:
1. Define the scoring scale explicitly (90-100 = exact match, 70-89 = strong, 50-69 = partial, 25-49 = weak, 0-24 = no match)
2. List all 5 dimensions with weights (specialization 30%, experience 25%, technical 20%, bar 15%, location 10%)
3. Instruct Claude to calculate weighted average for overallScore
4. Instruct Claude to provide recommendation based on overall score thresholds
5. Never reference PII in any way

**In `src/lib/matching/pre-filter.ts`:**

Add `import 'server-only'` at top.

Export `preFilterCandidates(job: JobForScoring & { requiredSpecializations: string[]; requiredBar: string[]; requiredTechnicalDomains: string[] }): Promise<string[]>`.

This function returns profile IDs of candidates who pass the pre-filter. Follow the exact EXISTS subquery pattern from `employer-profiles.ts` `buildFilterConditions`:

1. Base condition: `eq(profiles.status, 'active')`
2. If `requiredSpecializations` is non-empty: EXISTS subquery on `profileSpecializations` JOIN `specializations` where `specializations.name IN (requiredSpecializations)`. This checks that the candidate has AT LEAST ONE of the required specializations (OR logic, not AND -- finding anyone with overlap).
3. If `requiredBar` is non-empty: EXISTS subquery on `barAdmissions` where `barAdmissions.jurisdiction IN (requiredBar)`.
4. If `requiredTechnicalDomains` is non-empty: EXISTS subquery on `profileTechnicalDomains` JOIN `technicalDomains` where `technicalDomains.name IN (requiredTechnicalDomains)`.
5. If `minimumExperience` is set: DO NOT filter by experience in SQL (experience is computed from work_history dates in JS, same decision as [05-01-D2]). The pre-filter should be inclusive; experience scoring happens in the Claude scoring step.

Return `db.select({ id: profiles.id }).from(profiles).where(and(...conditions))` mapped to IDs.

If no requirement fields are set (all empty arrays and null), return all active profile IDs (the Claude scoring step will handle differentiation).

**In `src/lib/matching/score.ts`:**

Add `import 'server-only'` at top.

Export `scoreCandidate(job: JobForScoring, candidate: CandidateForScoring): Promise<MatchScore>`.

Replicate the EXACT pattern from `src/lib/cv-parser/parse.ts`:
1. Create `const anthropic = new Anthropic()` at module level
2. Call `anthropic.messages.create()` with:
   - `model: 'claude-haiku-4-5-20251001'`
   - `max_tokens: 1024`
   - `messages: [{ role: 'user', content: buildScoringPrompt(job, candidate) }]`
   - `output_config: { format: zodOutputFormat(MatchScoreSchema) }`
3. Parse the first content block as text
4. `MatchScoreSchema.parse(JSON.parse(firstBlock.text))` to get typed result
5. Return the parsed MatchScore

Import `zodOutputFormat` from `'@anthropic-ai/sdk/helpers/zod'` exactly as done in parse.ts.
  </action>
  <verify>Run `npx tsc --noEmit` to verify all 4 files compile. Verify that `CandidateForScoring` type has NO PII fields (no name, email, phone, employer). Verify the prompt contains explicit scoring scale definitions.</verify>
  <done>Four matching modules exist: schema.ts defines Zod output schema + scoring DTOs, prompt.ts builds the rubric prompt, pre-filter.ts eliminates mismatches via SQL, score.ts calls Claude API with structured output. No PII in any scoring path.</done>
</task>

<task type="auto">
  <name>Task 2: Create matching orchestrator and async API routes</name>
  <files>src/lib/matching/run-matching.ts, src/app/api/matching/run/route.ts, src/app/api/matching/status/route.ts</files>
  <action>
**In `src/lib/matching/run-matching.ts`:**

Add `import 'server-only'` at top.

Export `runMatchingForJob(jobId: string): Promise<{ matchCount: number; errors: string[] }>`.

This is the orchestrator that ties together pre-filter, scoring, and caching. Steps:

1. Load the job by ID using `getJobById` from the jobs DAL. If not found, throw error.
2. Update job `matchingStatus` to `'running'` using `updateJobMatchingStatus`.
3. Build `JobForScoring` from the job data (extract the requirement fields).
4. Call `preFilterCandidates()` to get shortlisted profile IDs.
5. For each profile ID in the shortlist:
   a. Check cache: call `getMatchByJobAndProfile(jobId, profileId)`. If cached and `scoredAt` is after the job's `updatedAt`, skip (cache hit).
   b. Load candidate data for scoring. Query the profile's related data (specializations, education, bar admissions, technical domains, work history for experience calculation) using `db.query.profiles.findFirst()` with relational includes. Compute `experienceYears` by summing work history durations (reuse the logic from `bucketExperienceYears` but get raw years, not bucketed string). Build `CandidateForScoring` -- NEVER include name/email/phone/employer names.
   c. Call `scoreCandidate(jobForScoring, candidateForScoring)`.
   d. Insert result using `insertMatch()` with `JSON.stringify(subscores)` for the subscores field (the subscores object is: `{ specializationMatch, experienceFit, technicalBackground, locationMatch, barAdmissions }` from the MatchScore, excluding overallScore/summary/recommendation which go in their own columns).
   e. If scoring throws an error for a single candidate, catch it, log it, add to errors array, and continue to next candidate. Do NOT abort the whole pipeline for one failure.
6. After all candidates processed, update job `matchingStatus` to `'completed'`.
7. If ALL candidates errored, set status to `'failed'`.
8. Return `{ matchCount, errors }`.

Wrap the entire function in a try/catch. On catch, set `matchingStatus` to `'failed'` and re-throw.

Helper function for computing raw experience years (not bucketed):
```typescript
function computeExperienceYears(workHistory: { startDate: string | null; endDate: string | null }[]): number {
  let totalMonths = 0
  for (const wh of workHistory) {
    if (!wh.startDate) continue
    const start = new Date(wh.startDate)
    const end = wh.endDate ? new Date(wh.endDate) : new Date()
    const months = (end.getFullYear() - start.getFullYear()) * 12 + (end.getMonth() - start.getMonth())
    totalMonths += Math.max(0, months)
  }
  return Math.round(totalMonths / 12)
}
```

**In `src/app/api/matching/run/route.ts`:**

Follow the pattern from `src/app/api/admin/cv/parse/route.ts`.

- `export const maxDuration = 120` (matching can take longer than CV parsing with many candidates)
- `POST` handler:
  1. Auth check: call `getUser()` from `@/lib/dal`. Allow both `admin` and `employer` roles.
  2. Parse request body for `{ jobId: string }`.
  3. If user is employer, verify they own the job (job.employerUserId === user.id).
  4. Check job exists and has status 'open'. If not open, return 400 error.
  5. Check matchingStatus is NOT 'running'. If running, return 409 conflict ("Matching already in progress").
  6. Fire-and-forget: call `runMatchingForJob(jobId)` WITHOUT awaiting. Use the same pattern as CV batch parsing -- start the async work and return immediately.

  Actually, since Next.js Edge Runtime doesn't support fire-and-forget well, use the simpler approach: call `runMatchingForJob(jobId)` and await it. Set `maxDuration = 120` so the serverless function has enough time. The frontend polls status separately.

  Return `{ success: true, message: 'Matching started' }` with 200 status.

  WAIT -- better approach following the EXACT CV parsing pattern: The parse route in this codebase actually DOES await the parsing synchronously. The "async" feeling comes from the frontend polling status. So: await `runMatchingForJob(jobId)` and return the result. The frontend triggers this via fetch and polls `/api/matching/status` for updates.

  CORRECTION: Looking at the parse route again, it's synchronous (awaits parseSingleCv). For matching many candidates, this could be slow. Use the same approach: await the full pipeline, set `maxDuration = 120`. The frontend starts the request and simultaneously polls status. When the request completes, it returns the full result. If the request times out, the frontend sees 'running' status and can retry later.

  Return `NextResponse.json({ success: true, matchCount, errors })`.

**In `src/app/api/matching/status/route.ts`:**

Follow the pattern from `src/app/api/admin/cv/status/route.ts`.

- `GET` handler:
  1. Auth check: call `getUser()`. Allow both admin and employer.
  2. Parse `jobId` from URL searchParams.
  3. Load job by ID using `getJobById`.
  4. If user is employer, verify ownership.
  5. Return `{ matchingStatus: job.matchingStatus, matchedAt: job.matchedAt, matchCount }`.
  6. To get matchCount without loading all matches, run `db.select({ count: sql<number>\`count(*)\` }).from(jobMatches).where(eq(jobMatches.jobId, jobId))`.

Return `NextResponse.json({ ... })`.
  </action>
  <verify>Run `npx tsc --noEmit` to verify all 3 files compile. Verify the run route has `maxDuration = 120`. Verify the status route returns matchingStatus and matchCount. Verify run-matching.ts catches per-candidate errors without aborting the pipeline.</verify>
  <done>Matching orchestrator runs pre-filter -> score -> cache pipeline. POST /api/matching/run triggers matching for a job (auth-gated, employer ownership checked). GET /api/matching/status polls matching progress. Pipeline handles per-candidate errors gracefully.</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes with zero errors
- `src/lib/matching/schema.ts` exports MatchScoreSchema, MatchScore, CandidateForScoring (no PII fields), JobForScoring
- `src/lib/matching/prompt.ts` exports buildScoringPrompt with explicit scoring scale
- `src/lib/matching/pre-filter.ts` exports preFilterCandidates using EXISTS subqueries
- `src/lib/matching/score.ts` exports scoreCandidate using Claude Haiku 4.5 + zodOutputFormat
- `src/lib/matching/run-matching.ts` exports runMatchingForJob orchestrator
- API routes exist at `/api/matching/run` and `/api/matching/status`
- No PII (name, email, phone, employer) appears in any scoring-related code
- Per-candidate errors don't crash the whole pipeline
</verification>

<success_criteria>
The complete matching pipeline is implemented: SQL pre-filter narrows candidates, Claude Haiku 4.5 scores the shortlist with structured output, results are cached in job_matches, and two API routes provide trigger and status polling. The pipeline never sends PII to the Claude API.
</success_criteria>

<output>
After completion, create `.planning/phases/08-job-posting-and-ai-matching/08-02-SUMMARY.md`
</output>

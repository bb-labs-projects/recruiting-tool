---
phase: 08-job-posting-and-ai-matching
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/db/schema.ts
  - src/lib/db/relations.ts
  - drizzle/0003_jobs_and_matches.sql
  - src/lib/dal/jobs.ts
  - src/lib/dal/job-matches.ts
autonomous: true

must_haves:
  truths:
    - "jobs and jobMatches tables exist in the database schema with all required columns"
    - "Drizzle relations link jobs to users, jobMatches to jobs and profiles"
    - "DAL module can create, read, update jobs with proper employer/admin access patterns"
    - "DAL module can read cached match results sorted by score"
  artifacts:
    - path: "src/lib/db/schema.ts"
      provides: "jobs table, jobMatches table, jobStatusEnum, matchingStatusEnum"
      contains: "export const jobs = pgTable"
    - path: "src/lib/db/relations.ts"
      provides: "jobsRelations, jobMatchesRelations with connections to users and profiles"
      contains: "jobsRelations"
    - path: "drizzle/0003_jobs_and_matches.sql"
      provides: "SQL migration for jobs and job_matches tables with enums and indexes"
      contains: "CREATE TABLE"
    - path: "src/lib/dal/jobs.ts"
      provides: "Job CRUD operations for employer and admin"
      exports: ["getJobsByEmployer", "getJobById", "getJobsForAdmin", "createJob", "updateJob"]
    - path: "src/lib/dal/job-matches.ts"
      provides: "Match result reading and cache management"
      exports: ["getMatchesForJob", "getMatchByJobAndProfile", "invalidateMatchesForJob"]
  key_links:
    - from: "src/lib/db/schema.ts"
      to: "src/lib/db/relations.ts"
      via: "jobs and jobMatches table exports used in relations"
      pattern: "import.*jobs.*jobMatches.*from.*schema"
    - from: "src/lib/dal/jobs.ts"
      to: "src/lib/db/schema.ts"
      via: "Drizzle queries against jobs table"
      pattern: "from\\(jobs\\)|db\\.query\\.jobs"
    - from: "src/lib/dal/job-matches.ts"
      to: "src/lib/db/schema.ts"
      via: "Drizzle queries against jobMatches table"
      pattern: "from\\(jobMatches\\)|db\\.query\\.jobMatches"
---

<objective>
Add jobs and jobMatches database tables, Drizzle relations, SQL migration, and DAL modules for job CRUD and match result reading.

Purpose: This is the data foundation for the entire job posting and AI matching feature. Every subsequent plan depends on these tables and DAL functions.
Output: Schema tables with enums/indexes, Drizzle relations, migration SQL, and two DAL modules (jobs.ts for CRUD, job-matches.ts for match results).
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-job-posting-and-ai-matching/08-RESEARCH.md

Key reference files:
@src/lib/db/schema.ts -- existing schema patterns (pgEnum, pgTable, indexes, references)
@src/lib/db/relations.ts -- existing relation patterns
@src/lib/dal/employer-profiles.ts -- DAL pattern with cache(), 'server-only', DTOs
@src/lib/dal/employer-unlocks.ts -- simple DAL query pattern
@drizzle/0002_candidate_profile_ownership.sql -- existing migration SQL pattern
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add jobs and jobMatches tables with enums to schema.ts and relations.ts</name>
  <files>src/lib/db/schema.ts, src/lib/db/relations.ts, drizzle/0003_jobs_and_matches.sql</files>
  <action>
**In `src/lib/db/schema.ts`:**

Add two new enums BEFORE the tables section:

```typescript
export const jobStatusEnum = pgEnum('job_status', ['draft', 'open', 'closed', 'archived'])
export const matchingStatusEnum = pgEnum('matching_status', ['pending', 'running', 'completed', 'failed'])
```

Add the `jobs` table after `profileViews`:

```typescript
export const jobs = pgTable('jobs', {
  id: uuid('id').defaultRandom().primaryKey(),
  employerUserId: uuid('employer_user_id')
    .notNull()
    .references(() => users.id, { onDelete: 'cascade' }),
  title: varchar('title', { length: 255 }).notNull(),
  description: text('description'),
  status: jobStatusEnum('status').notNull().default('draft'),
  matchingStatus: matchingStatusEnum('matching_status').notNull().default('pending'),
  requiredSpecializations: text('required_specializations').array(),
  preferredSpecializations: text('preferred_specializations').array(),
  minimumExperience: integer('minimum_experience'),
  preferredLocation: varchar('preferred_location', { length: 255 }),
  requiredBar: text('required_bar').array(),
  requiredTechnicalDomains: text('required_technical_domains').array(),
  createdBy: uuid('created_by')
    .notNull()
    .references(() => users.id),
  createdAt: timestamp('created_at', { withTimezone: true }).defaultNow().notNull(),
  updatedAt: timestamp('updated_at', { withTimezone: true }).defaultNow().notNull(),
  matchedAt: timestamp('matched_at', { withTimezone: true }),
}, (table) => [
  index('jobs_employer_idx').on(table.employerUserId),
  index('jobs_status_idx').on(table.status),
])
```

Add the `jobMatches` table after `jobs`:

```typescript
export const jobMatches = pgTable('job_matches', {
  id: uuid('id').defaultRandom().primaryKey(),
  jobId: uuid('job_id')
    .notNull()
    .references(() => jobs.id, { onDelete: 'cascade' }),
  profileId: uuid('profile_id')
    .notNull()
    .references(() => profiles.id, { onDelete: 'cascade' }),
  overallScore: integer('overall_score').notNull(),
  subscores: text('subscores').notNull(),
  summary: text('summary').notNull(),
  recommendation: varchar('recommendation', { length: 50 }).notNull(),
  scoredAt: timestamp('scored_at', { withTimezone: true }).defaultNow().notNull(),
  notifiedAt: timestamp('notified_at', { withTimezone: true }),
}, (table) => [
  uniqueIndex('job_matches_job_profile_idx').on(table.jobId, table.profileId),
  index('job_matches_job_idx').on(table.jobId),
  index('job_matches_profile_idx').on(table.profileId),
  index('job_matches_score_idx').on(table.jobId, table.overallScore),
])
```

**In `src/lib/db/relations.ts`:**

Add imports for `jobs` and `jobMatches` from `./schema`.

Add relations:

```typescript
export const jobsRelations = relations(jobs, ({ one, many }) => ({
  employer: one(users, {
    fields: [jobs.employerUserId],
    references: [users.id],
    relationName: 'jobEmployer',
  }),
  creator: one(users, {
    fields: [jobs.createdBy],
    references: [users.id],
    relationName: 'jobCreator',
  }),
  matches: many(jobMatches),
}))

export const jobMatchesRelations = relations(jobMatches, ({ one }) => ({
  job: one(jobs, {
    fields: [jobMatches.jobId],
    references: [jobs.id],
  }),
  profile: one(profiles, {
    fields: [jobMatches.profileId],
    references: [profiles.id],
  }),
}))
```

Also update the existing `profilesRelations` to add `jobMatches: many(jobMatches)` and update `usersRelations` to add `jobs: many(jobs)`.

**In `drizzle/0003_jobs_and_matches.sql`:**

Write the raw SQL migration that creates:
1. The `job_status` enum type
2. The `matching_status` enum type
3. The `jobs` table with all columns and indexes
4. The `job_matches` table with all columns, unique index, and regular indexes

Follow the pattern from `0002_candidate_profile_ownership.sql`. Include comments explaining the migration.
  </action>
  <verify>Run `npx tsc --noEmit` to verify schema.ts and relations.ts compile without errors. Verify the SQL migration file is valid SQL syntax by visual inspection.</verify>
  <done>schema.ts exports jobs, jobMatches, jobStatusEnum, matchingStatusEnum. relations.ts has jobsRelations and jobMatchesRelations. Migration SQL file creates both tables with proper enums, constraints, and indexes.</done>
</task>

<task type="auto">
  <name>Task 2: Create DAL modules for job CRUD and match result reading</name>
  <files>src/lib/dal/jobs.ts, src/lib/dal/job-matches.ts</files>
  <action>
**In `src/lib/dal/jobs.ts`:**

Create a DAL module following the pattern from `employer-profiles.ts`: `import 'server-only'`, `cache()` wrapper for reads, typed DTOs.

Export these functions:

1. `getJobsByEmployer(employerUserId: string)` -- returns all jobs for an employer, ordered by createdAt DESC. Include match count via a subquery or relational query. Return type: `JobListDTO[]` with fields: `id, title, status, matchingStatus, matchCount, createdAt, updatedAt`.

2. `getJobById(jobId: string)` -- returns a single job with all fields. Used by both employer detail page and matching pipeline. Return type: `JobDetailDTO | null` with all job columns plus `employerEmail` (joined from users table, needed for notifications).

3. `getJobsForAdmin()` -- returns all jobs across all employers for admin management. Include employer company name (join through users -> employerProfiles). Return type: `AdminJobListDTO[]` with fields: `id, title, status, matchingStatus, employerCompanyName, matchCount, createdAt`.

4. `getOpenJobsForMatching()` -- returns jobs with status 'open' that need matching (matchingStatus is 'pending' or matching was run long ago). Lightweight: returns only the fields needed for the pre-filter step. Used by the matching pipeline, not by UI.

5. `createJob(data: CreateJobInput)` -- inserts a new job. Input type includes all requirement fields plus `employerUserId` and `createdBy`. Returns the inserted job ID.

6. `updateJob(jobId: string, data: UpdateJobInput)` -- updates a job. Sets `updatedAt` to `new Date()`. If status changes or requirements change, also resets `matchingStatus` to 'pending' so matching can be re-triggered.

7. `updateJobMatchingStatus(jobId: string, status: 'pending' | 'running' | 'completed' | 'failed')` -- updates just the matchingStatus field. If status is 'completed', also sets `matchedAt` to `new Date()`.

Types for `CreateJobInput` and `UpdateJobInput` should use Partial patterns or explicit field lists. Do NOT use Zod here -- validation happens in server actions. The DAL assumes valid data.

**In `src/lib/dal/job-matches.ts`:**

Create a DAL module for reading match results. Follow the same pattern.

Export these functions:

1. `getMatchesForJob(jobId: string)` -- returns all matches for a job, ordered by overallScore DESC. Parse the `subscores` JSON string back into a typed object. Return type: `JobMatchDTO[]` with fields: `id, profileId, overallScore, subscores (parsed object), summary, recommendation, scoredAt, notifiedAt`.

2. `getMatchByJobAndProfile(jobId: string, profileId: string)` -- checks if a cached match exists. Returns `JobMatchDTO | null`. Used by the matching pipeline to skip already-scored candidates.

3. `insertMatch(data: InsertMatchInput)` -- inserts a new match result. The `subscores` field should be `JSON.stringify()`'d before insert. Uses `onConflictDoUpdate` on the unique (jobId, profileId) index to update if re-scored.

4. `invalidateMatchesForJob(jobId: string)` -- deletes all cached matches for a job. Called when job requirements change. Simple `db.delete(jobMatches).where(eq(jobMatches.jobId, jobId))`.

5. `getUnnotifiedMatches(jobId: string, minScore?: number)` -- returns matches where `notifiedAt IS NULL` and optionally `overallScore >= minScore`. Used by the notification system to avoid re-notifying.

6. `markMatchesNotified(matchIds: string[])` -- sets `notifiedAt = new Date()` for the given match IDs. Called after sending notification emails.

For the `subscores` parsed type, define a `MatchSubscores` type matching the scoring rubric:
```typescript
type MatchSubscores = {
  specializationMatch: { score: number; explanation: string }
  experienceFit: { score: number; explanation: string }
  technicalBackground: { score: number; explanation: string }
  locationMatch: { score: number; explanation: string }
  barAdmissions: { score: number; explanation: string }
}
```
  </action>
  <verify>Run `npx tsc --noEmit` to verify both DAL files compile without errors. Verify imports are correct and all exported functions match the described signatures.</verify>
  <done>jobs.ts exports 7 functions for job CRUD with proper DTOs. job-matches.ts exports 6 functions for match result CRUD with parsed subscores. Both use 'server-only' and follow existing DAL patterns.</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes with zero errors
- `src/lib/db/schema.ts` exports `jobs`, `jobMatches`, `jobStatusEnum`, `matchingStatusEnum`
- `src/lib/db/relations.ts` defines `jobsRelations` and `jobMatchesRelations`
- `drizzle/0003_jobs_and_matches.sql` contains valid CREATE TABLE statements
- `src/lib/dal/jobs.ts` exports all 7 CRUD functions
- `src/lib/dal/job-matches.ts` exports all 6 match result functions
- No circular imports between new files
</verification>

<success_criteria>
Schema tables, relations, migration SQL, and DAL modules are complete and type-check cleanly. All downstream plans (matching pipeline, employer UI, admin UI) can import from these files.
</success_criteria>

<output>
After completion, create `.planning/phases/08-job-posting-and-ai-matching/08-01-SUMMARY.md`
</output>
